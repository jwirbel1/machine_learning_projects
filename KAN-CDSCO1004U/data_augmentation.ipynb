{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from PIL import Image, ImageEnhance, ImageFilter, ImageOps\n",
    "from skimage import exposure\n",
    "from skimage.color import rgb2gray\n",
    "import cv2\n",
    "import math\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_function(edge_enhance, equalization, blur, image):\n",
    "\n",
    "    # apply gaussian blur to the image\n",
    "    image = cv2.GaussianBlur(image, (blur, blur), 0 )\n",
    "    # edge enhance using PIL\n",
    "    if edge_enhance:\n",
    "        image = Image.fromarray(image)\n",
    "        image = image.filter(ImageFilter.EDGE_ENHANCE)\n",
    "        image = np.array(image)\n",
    "    else:\n",
    "        image = image\n",
    "    \n",
    "    # equalization\n",
    "    if equalization == 'histogram':\n",
    "        image = cv2.equalizeHist(image)\n",
    "    elif equalization == 'adaptive':\n",
    "        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "        image = clahe.apply(image)\n",
    "    else: \n",
    "        image = image\n",
    "    # rotate\n",
    "    image = image\n",
    "    image1 = cv2.flip(image, 1)\n",
    "\n",
    "    return image, image1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_image(img):\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # threshold \n",
    "    thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY+cv2.THRESH_OTSU)[1]\n",
    "    hh, ww = thresh.shape\n",
    "\n",
    "    # make bottom 2 rows black where they are white the full width of the image\n",
    "    thresh[hh-3:hh, 0:ww] = 0\n",
    "\n",
    "    # get bounds of white pixels\n",
    "    white = np.where(thresh==255)\n",
    "    xmin, ymin, xmax, ymax = np.min(white[1]), np.min(white[0]), np.max(white[1]), np.max(white[0])\n",
    "    hd = ymax-ymin\n",
    "    wd = xmax-xmin\n",
    "    g = 0 \n",
    "    j = 0\n",
    "    m = 0\n",
    "    f = 0\n",
    "    if hd > wd and (ymin <2 or ymax + 2 > img.shape[0]):\n",
    "        g = 0\n",
    "        j = 0\n",
    "        t = (hd-wd) / 2 \n",
    "        if xmin - math.floor(t) >= 0 and xmax + math.ceil(t) <= img.shape[1]:\n",
    "            m = math.floor(t)\n",
    "            f = math.ceil(t)\n",
    "        elif xmin - math.floor(t) >= 0:\n",
    "            f = img.shape[1]-xmax\n",
    "            m = ((2*t)-f)\n",
    "        else:\n",
    "            m = xmin\n",
    "            f = ((2*t)-m)\n",
    "    elif hd > wd and (ymin >= 2 or ymax + 2 <= img.shape[0]):\n",
    "        g = 2\n",
    "        j = 2\n",
    "        t = ((hd+4)-wd) / 2\n",
    "        if xmin - math.floor(t) >= 0 and xmax + math.ceil(t) <= img.shape[1]:\n",
    "            m = math.floor(t)\n",
    "            f = math.ceil(t)\n",
    "        elif xmin - math.floor(t) >= 0:\n",
    "            f = img.shape[1]-xmax\n",
    "            m = ((2*t)-f)\n",
    "        else:\n",
    "            m = xmin\n",
    "            f = ((2*t)-m)\n",
    "    elif wd > hd and (xmin < 2 or xmax +2 > img.shape[1]):\n",
    "        m = 0 \n",
    "        f = 0\n",
    "        t = (wd-hd) / 2 \n",
    "        if ymin - math.floor(t) >= 0 and ymax + math.ceil(t) <= img.shape[0]:\n",
    "            g = math.floor(t)\n",
    "            j = math.ceil(t)\n",
    "        elif ymin - math.floor(t) >= 0:\n",
    "            j = img.shape[0]-ymax\n",
    "            g = ((2*t)-j)\n",
    "        else:\n",
    "            g = ymin\n",
    "            j = ((2*t)-g)\n",
    "    elif wd > hd and (xmin >= 2 or xmax + 2 <= img.shape[1]):\n",
    "        m = 2 \n",
    "        f = 2\n",
    "        t = ((wd+4)-hd) / 2 \n",
    "        if ymin - math.floor(t) >= 0 and ymax + math.ceil(t) <= img.shape[0]:\n",
    "            g = math.floor(t)\n",
    "            j = math.ceil(t)\n",
    "        elif ymin - math.floor(t) >= 0:\n",
    "            j = img.shape[0]-ymax\n",
    "            g = ((2*t)-j)\n",
    "        else:\n",
    "            g = ymin\n",
    "            j = ((2*t)-g)\n",
    "    elif wd == hd:\n",
    "      if wd + 4 <= img.shape[1] and hd + 4 <= img.shape[0]:\n",
    "        g = 2 \n",
    "        j = 2\n",
    "        m = 2\n",
    "        f = 2\n",
    "      else: \n",
    "        g = 0 \n",
    "        j = 0\n",
    "        m = 0\n",
    "        f = 0\n",
    "    # crop the image at the bounds adding back the two blackened rows at the bottom\n",
    "    if hd + 4 > img.shape[1] or wd + 4 > img.shape[0]:\n",
    "        crop = img[:,:,0]\n",
    "    elif hd == 0 or wd == 0:\n",
    "        crop = img[:,:,0]\n",
    "    else:\n",
    "        xx = int(ymin-g)\n",
    "        xy = int(ymax+j)\n",
    "        yx = int(xmin-m)\n",
    "        yy = int(xmax+f)\n",
    "        crop = img[xx:xy, yx:yy,0]\n",
    "    if crop.shape[0] != crop.shape[1]:\n",
    "      crop = img[:,:,0]\n",
    "    return crop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/dmc/ml_storage/machine_learning/Final_ML_CBS/data/age/'\n",
    "target_path = '/dmc/ml_storage/machine_learning/Final_ML_CBS/data/age_prep/'\n",
    "\n",
    "\n",
    "# equalization: histogram or adaptive\n",
    "preprocessing_args = {\n",
    "    'edge_enhance': True,\n",
    "    'equalization': 'histogram',\n",
    "    'blur': 7\n",
    "}\n",
    "errors = []\n",
    "shape = []\n",
    "for folder in os.listdir(data_dir):\n",
    "    # add folder to the data_dir path\n",
    "    folder_path = data_dir + folder + '/'\n",
    "    for image in os.listdir(folder_path):\n",
    "        try:\n",
    "            img = cv2.imread(folder_path + image, cv2.COLOR_BGR2GRAY)\n",
    "            # cropping \n",
    "            print(folder_path + image)\n",
    "            img = crop_image(img)\n",
    "            # check that the image has no 0 in its shape, if so. reload it\n",
    "            if 0 in img.shape:\n",
    "                img = cv2.imread(folder_path + image, cv2.COLOR_BGR2GRAY)\n",
    "                img = img[:,:,0]\n",
    "\n",
    "            temp, temp1 = preprocessing_function(preprocessing_args['edge_enhance'],  \n",
    "                                          preprocessing_args['equalization'],\n",
    "                                          preprocessing_args['blur'],\n",
    "                                          img)\n",
    "\n",
    "            # add a _i to the image name\n",
    "            path = target_path + folder + '/' + image[:-4] + '_0.png'\n",
    "            cv2.imwrite(path, temp)\n",
    "            path1 = target_path + folder + '/' + image[:-4] + '_1.png'\n",
    "            cv2.imwrite(path1, temp1)\n",
    "            shape.append([temp.shape,temp1.shape])\n",
    "        except Exception as e:\n",
    "            errors.append([e, folder_path + image])\n",
    "            print(\"error\")\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors = pd.DataFrame(errors, columns=['error', 'path'])\n",
    "errors.to_csv('errors.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getthe first error\n",
    "errors.iloc[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "gpu_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "for device in gpu_devices:\n",
    "    tf.config.experimental.set_memory_growth(device, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = 224\n",
    "input_dim = (size, size, 1)\n",
    "classes = 30\n",
    "batch_size = 8\n",
    "data_dir = '/dmc/ml_storage/machine_learning/Final_ML_CBS/data/cohorts_5_aug/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "  data_dir,\n",
    "  subset='training',\n",
    "  validation_split=0.2,\n",
    "  labels = 'inferred',\n",
    "  label_mode='categorical',\n",
    "  seed=42,\n",
    "  image_size=(size, size),\n",
    "  batch_size=batch_size,\n",
    "  color_mode='grayscale')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "  data_dir,\n",
    "  subset='validation',\n",
    "  validation_split=0.2,\n",
    "  labels = 'inferred',\n",
    "  label_mode='categorical',\n",
    "  seed=42,\n",
    "  image_size=(size, size),\n",
    "  batch_size=batch_size, \n",
    "  color_mode='grayscale')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the class names\n",
    "class_names = train_ds.class_names\n",
    "print(class_names)\n",
    "# show the shape of the training and validation datasets\n",
    "\n",
    "for image_batch, labels_batch in train_ds:\n",
    "    print(image_batch.shape)\n",
    "    print(labels_batch.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "for images, labels in train_ds.take(1):\n",
    "  for i in range(batch_size):\n",
    "    ax = plt.subplot(3, 3, i + 1)\n",
    "    plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "    plt.title(class_names[np.argmax(labels[i])])\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Conv2D, Dropout, Flatten, BatchNormalization, MaxPooling2D, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "\n",
    "input = Input(shape=input_dim)\n",
    "\n",
    "conv1 = Conv2D(64, kernel_size=(3, 3), activation='relu', padding='same')(input)\n",
    "conv1 = Conv2D(64, kernel_size=(3, 3), activation='relu', padding='same')(conv1)\n",
    "conv1 = Dropout(0.1)(conv1)\n",
    "mpool1 = MaxPooling2D()(conv1)\n",
    "\n",
    "conv2 = Conv2D(128, kernel_size=(3, 3), activation='relu', padding='same')(mpool1)\n",
    "conv2 = Conv2D(128, kernel_size=(3, 3), activation='relu', padding='same')(conv2)\n",
    "conv2 = Dropout(0.2)(conv2)\n",
    "mpool2 = MaxPooling2D()(conv2)\n",
    "\n",
    "conv3 = Conv2D(256, kernel_size=(3, 3), activation='relu', padding='same')(mpool2)\n",
    "conv3 = Conv2D(256, kernel_size=(3, 3), activation='relu', padding='same')(conv3)\n",
    "conv3 = Dropout(0.3)(conv3)\n",
    "mpool3 = MaxPooling2D()(conv3)\n",
    "\n",
    "conv4 = Conv2D(512, 3, activation='relu', padding='same')(mpool3)\n",
    "conv4 = Conv2D(512, 3, activation='relu', padding='same')(conv4)\n",
    "conv4 = Dropout(0.4)(conv4)\n",
    "mpool4 = MaxPooling2D()(conv4)\n",
    "# get the output of the base model\n",
    "\n",
    "# Net 1 for age\n",
    "net_1_conv1 = Conv2D(512, kernel_size=(3, 3), activation='relu', padding = 'same')(mpool4)\n",
    "net_1_conv2 = Conv2D(512, kernel_size=(3, 3), activation='relu', padding = 'same')(net_1_conv1)\n",
    "net_1_drop1 = Dropout(0.2)(net_1_conv2)\n",
    "net_1_pool1 = MaxPooling2D(pool_size = (3, 3), padding = 'same')(net_1_drop1)\n",
    "\n",
    "net_1_conv3 = Conv2D(512, kernel_size=(3, 3), strides=(1,1), activation='relu', padding = 'same')(net_1_pool1)\n",
    "net_1_drop2 = Dropout(rate=0.2)(net_1_conv3)\n",
    "\n",
    "net_1_conv4 = Conv2D(1024, kernel_size=(3, 3), strides=(1,1), activation='relu')(net_1_drop2)\n",
    "net_1_drop3 = Dropout(rate=0.4)(net_1_conv4)\n",
    "\n",
    "net_1_conv5 = Conv2D(1024, kernel_size=(3, 3), strides=(1,1), activation='relu')(net_1_drop3)\n",
    "net_1_drop4 = Dropout(rate=0.2)(net_1_conv5)\n",
    "\n",
    "# Inference layer\n",
    "net_1_batch = BatchNormalization()(net_1_drop4)\n",
    "flatten1 = Flatten()(net_1_batch)\n",
    "out1 = Dense(classes, activation='softmax', name='age')(flatten1)\n",
    "\n",
    "model = Model(inputs=input, outputs=out1)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write a function to delete the model and all layers\n",
    "def delete_model(model):\n",
    "    del model\n",
    "    tf.keras.backend.clear_session()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [ModelCheckpoint('cohorts.hdf5', verbose=1, save_best_only=True, save_weights_only=True,\n",
    "                             monitor = 'val_loss'),\n",
    "             EarlyStopping(monitor = 'val_loss', patience = 16, restore_best_weights = True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
    "    loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "    metrics=['accuracy', tf.keras.metrics.Precision(), tf.keras.metrics.Recall(), tf.keras.metrics.AUC()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "# just use a sample of the training data for now\n",
    "\n",
    "\n",
    "train_ds = train_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 32\n",
    "history = model.fit(train_ds,  validation_data=val_ds,\n",
    "            batch_size=batch_size, \n",
    "            epochs=epochs, \n",
    "            shuffle=True,\n",
    "            callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['loss'], label='train_loss')\n",
    "plt.plot(history.history['val_loss'], label='val_loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a table with accuracy, precision, recall and f1-score on the val set\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# load the best model\n",
    "model.load_weights('cohorts.hdf5')\n",
    "\n",
    "# get the predictions\n",
    "y_pred = model.predict(val_ds)\n",
    "y_pred = np.argmax(y_pred, axis=1)\n",
    "\n",
    "# get the true labels\n",
    "y_true = []\n",
    "for images, labels in val_ds:\n",
    "    y_true.append(labels.numpy())\n",
    "y_true = np.concatenate(y_true)\n",
    "y_true = np.argmax(y_true, axis=1)\n",
    "\n",
    "# get the classification report\n",
    "report = classification_report(y_true, y_pred, target_names=class_names, output_dict=True)\n",
    "report = pd.DataFrame(report).transpose()\n",
    "\n",
    "output = [report, history.history['loss'], history.history['val_loss']]\n",
    "\n",
    "# conert the output to a dataframe\n",
    "output = pd.DataFrame(output)\n",
    "# name the columns\n",
    "output.index = ['classification_report', 'train_loss', 'val_loss']\n",
    "\n",
    "output.to_csv('None_False_ad.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
